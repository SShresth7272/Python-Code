{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkuER1dw0aK+ao4+wLwxSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SShresth7272/Python-Code/blob/main/Machine_Learning_Multi_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FXiwdM4mHUXS"
      },
      "outputs": [],
      "source": [
        "# Multiclass Classification\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_classification, load_iris, load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    roc_curve, auc, roc_auc_score,\n",
        "    classification_report, confusion_matrix,\n",
        "    precision_recall_curve, average_precision_score\n",
        ")\n",
        "from sklearn.preprocessing import LabelBinarizer, label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for better plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "print(\"One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def create_health_dataset():\n",
        "    \"\"\"Create a synthetic health diagnosis dataset\"\"\"\n",
        "    print(\"\\n1. HEALTH DOMAIN: Disease Diagnosis Prediction\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Simulate patient data: age, blood_pressure, cholesterol, blood_sugar, bmi\n",
        "    X, y = make_classification(\n",
        "        n_samples=1000, n_features=5, n_informative=5, n_redundant=0,\n",
        "        n_classes=3, n_clusters_per_class=1, random_state=42\n",
        "    )\n",
        "\n",
        "    # Transform features to realistic ranges\n",
        "    X[:, 0] = X[:, 0] * 30 + 40  # Age: 40-70\n",
        "    X[:, 1] = X[:, 1] * 40 + 80  # BP: 80-160\n",
        "    X[:, 2] = X[:, 2] * 100 + 150  # Cholesterol: 150-250\n",
        "    X[:, 3] = X[:, 3] * 50 + 80   # Blood sugar: 80-180\n",
        "    X[:, 4] = X[:, 4] * 10 + 25   # BMI: 25-35\n",
        "\n",
        "    class_names = ['Healthy', 'Hypertension', 'Diabetes']\n",
        "    feature_names = ['Age', 'Blood Pressure', 'Cholesterol', 'Blood Sugar', 'BMI']\n",
        "\n",
        "    return X, y, class_names, feature_names, \"Health Diagnosis\"\n",
        "\n",
        "def evaluate_strategies(X, y, class_names, feature_names, domain_name):\n",
        "    \"\"\"Evaluates OvO and OvR strategies on a given dataset\"\"\"\n",
        "    print(f\"\\nEvaluating on {domain_name} dataset...\")\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # OvO Strategy\n",
        "    print(\"Training OvO Classifier...\")\n",
        "    ovo_classifier = OneVsOneClassifier(LogisticRegression(solver='liblinear'))\n",
        "    ovo_classifier.fit(X_train, y_train)\n",
        "    ovo_score = ovo_classifier.score(X_test, y_test)\n",
        "    print(f\"OvO Accuracy: {ovo_score:.4f}\")\n",
        "\n",
        "    # OvR Strategy\n",
        "    print(\"Training OvR Classifier...\")\n",
        "    ovr_classifier = OneVsRestClassifier(LogisticRegression(solver='liblinear'))\n",
        "    ovr_classifier.fit(X_train, y_train)\n",
        "    ovr_score = ovr_classifier.score(X_test, y_test)\n",
        "    print(f\"OvR Accuracy: {ovr_score:.4f}\")\n",
        "\n",
        "    return ovo_score, ovr_score\n",
        "\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Create datasets from different domains\n",
        "    datasets = [\n",
        "        create_health_dataset(),\n",
        "\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Evaluate each dataset\n",
        "    for dataset in datasets:\n",
        "        X, y, class_names, feature_names, domain_name = dataset\n",
        "        ovo_score, ovr_score = evaluate_strategies(X, y, class_names, feature_names, domain_name)\n",
        "        results.append({\n",
        "            'Domain': domain_name,\n",
        "            'OvO_Accuracy': ovo_score,\n",
        "            'OvR_Accuracy': ovr_score,\n",
        "            'Best_Strategy': 'OvO' if ovo_score >= ovr_score else 'OvR'\n",
        "        })\n",
        "\n",
        "    # Summary comparison\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY COMPARISON ACROSS DOMAINS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Overall analysis\n",
        "    ovo_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvO')\n",
        "    ovr_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvR')\n",
        "\n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"OvO was better in {ovo_wins} out of {len(datasets)} domains\")\n",
        "    print(f\"OvR was better in {ovr_wins} out of {len(datasets)} domains\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rCK_EErK6Cv",
        "outputId": "fd50926c-6258-4448-c8dd-c3f877a0495f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\n",
            "=======================================================\n",
            "\n",
            "1. HEALTH DOMAIN: Disease Diagnosis Prediction\n",
            "---------------------------------------------\n",
            "\n",
            "Evaluating on Health Diagnosis dataset...\n",
            "Training OvO Classifier...\n",
            "OvO Accuracy: 0.9400\n",
            "Training OvR Classifier...\n",
            "OvR Accuracy: 0.9167\n",
            "\n",
            "============================================================\n",
            "SUMMARY COMPARISON ACROSS DOMAINS\n",
            "============================================================\n",
            "          Domain  OvO_Accuracy  OvR_Accuracy Best_Strategy\n",
            "Health Diagnosis          0.94      0.916667           OvO\n",
            "\n",
            "Overall Performance:\n",
            "OvO was better in 1 out of 1 domains\n",
            "OvR was better in 0 out of 1 domains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "print(\"One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def create_finance_dataset():\n",
        "    \"\"\"Create a synthetic financial risk assessment dataset\"\"\"\n",
        "    print(\"\\n2. FINANCE DOMAIN: Credit Risk Assessment\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Simulate financial data: income, credit_score, debt_to_income, employment_years, savings\n",
        "    X, y = make_classification(\n",
        "        n_samples=800, n_features=5, n_informative=5, n_redundant=0,\n",
        "        n_classes=4, n_clusters_per_class=1, random_state=42\n",
        "    )\n",
        "\n",
        "    # Transform to realistic financial ranges\n",
        "    X[:, 0] = X[:, 0] * 40000 + 50000  # Income: 50k-90k\n",
        "    X[:, 1] = X[:, 1] * 200 + 600      # Credit score: 600-800\n",
        "    X[:, 2] = (X[:, 2] * 0.3 + 0.2) * 100  # Debt-to-income: 20%-50%\n",
        "    X[:, 3] = X[:, 3] * 10 + 5         # Employment years: 5-15\n",
        "    X[:, 4] = X[:, 4] * 50000 + 20000  # Savings: 20k-70k\n",
        "\n",
        "    class_names = ['Low Risk', 'Medium Risk', 'High Risk', 'Very High Risk']\n",
        "    feature_names = ['Income', 'Credit Score', 'Debt-to-Income Ratio', 'Employment Years', 'Savings']\n",
        "\n",
        "    return X, y, class_names, feature_names, \"Credit Risk\"\n",
        "\n",
        "    # Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Create datasets from different domains\n",
        "    datasets = [\n",
        "        create_finance_dataset(),\n",
        "\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Evaluate each dataset\n",
        "    for dataset in datasets:\n",
        "        X, y, class_names, feature_names, domain_name = dataset\n",
        "        ovo_score, ovr_score = evaluate_strategies(X, y, class_names, feature_names, domain_name)\n",
        "        results.append({\n",
        "            'Domain': domain_name,\n",
        "            'OvO_Accuracy': ovo_score,\n",
        "            'OvR_Accuracy': ovr_score,\n",
        "            'Best_Strategy': 'OvO' if ovo_score >= ovr_score else 'OvR'\n",
        "        })\n",
        "\n",
        "    # Summary comparison\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY COMPARISON ACROSS DOMAINS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Overall analysis\n",
        "    ovo_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvO')\n",
        "    ovr_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvR')\n",
        "\n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"OvO was better in {ovo_wins} out of {len(datasets)} domains\")\n",
        "    print(f\"OvR was better in {ovr_wins} out of {len(datasets)} domains\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxU_i_U5TZ0Q",
        "outputId": "1c55a2d7-a23f-4abd-cc27-9fae3d3c9dc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\n",
            "=======================================================\n",
            "\n",
            "2. FINANCE DOMAIN: Credit Risk Assessment\n",
            "---------------------------------------------\n",
            "\n",
            "Evaluating on Credit Risk dataset...\n",
            "Training OvO Classifier...\n",
            "OvO Accuracy: 0.7542\n",
            "Training OvR Classifier...\n",
            "OvR Accuracy: 0.7083\n",
            "\n",
            "============================================================\n",
            "SUMMARY COMPARISON ACROSS DOMAINS\n",
            "============================================================\n",
            "     Domain  OvO_Accuracy  OvR_Accuracy Best_Strategy\n",
            "Credit Risk      0.754167      0.708333           OvO\n",
            "\n",
            "Overall Performance:\n",
            "OvO was better in 1 out of 1 domains\n",
            "OvR was better in 0 out of 1 domains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "print(\"One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "\n",
        "\n",
        "def create_marketing_dataset():\n",
        "    \"\"\"Create a synthetic customer segmentation dataset\"\"\"\n",
        "    print(\"\\n3. MARKETING DOMAIN: Customer Segmentation\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Simulate customer data: age, income, spending_score, loyalty_years, online_activity\n",
        "    X, y = make_classification(\n",
        "        n_samples=1200, n_features=5, n_informative=5, n_redundant=0,\n",
        "        n_classes=3, n_clusters_per_class=1, random_state=42\n",
        "    )\n",
        "\n",
        "    # Transform to realistic marketing ranges\n",
        "    X[:, 0] = X[:, 0] * 30 + 25       # Age: 25-55\n",
        "    X[:, 1] = X[:, 1] * 50000 + 50000 # Income: 50k-100k\n",
        "    X[:, 2] = X[:, 2] * 50 + 50       # Spending score: 50-100\n",
        "    X[:, 3] = X[:, 3] * 5 + 1         # Loyalty years: 1-6\n",
        "    X[:, 4] = X[:, 4] * 20 + 10       # Online activity: 10-30 hours/month\n",
        "\n",
        "    class_names = ['Budget Shopper', 'Quality Seeker', 'Premium Customer']\n",
        "    feature_names = ['Age', 'Annual Income', 'Spending Score', 'Loyalty Years', 'Online Activity']\n",
        "\n",
        "    return X, y, class_names, feature_names, \"Customer Segmentation\"\n",
        "\n",
        "    # Evaluate each dataset\n",
        "    for dataset in datasets:\n",
        "        X, y, class_names, feature_names, domain_name = dataset\n",
        "        ovo_score, ovr_score = evaluate_strategies(X, y, class_names, feature_names, domain_name)\n",
        "        results.append({\n",
        "            'Domain': domain_name,\n",
        "            'OvO_Accuracy': ovo_score,\n",
        "            'OvR_Accuracy': ovr_score,\n",
        "            'Best_Strategy': 'OvO' if ovo_score >= ovr_score else 'OvR'\n",
        "        })\n",
        "\n",
        "        # Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Create datasets from different domains\n",
        "    datasets = [\n",
        "        create_marketing_dataset(),\n",
        "\n",
        "    ]\n",
        "\n",
        "    # Summary comparison\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY COMPARISON ACROSS DOMAINS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Overall analysis\n",
        "    ovo_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvO')\n",
        "    ovr_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvR')\n",
        "\n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"OvO was better in {ovo_wins} out of {len(datasets)} domains\")\n",
        "    print(f\"OvR was better in {ovr_wins} out of {len(datasets)} domains\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwC4fAO5UfgC",
        "outputId": "1d715461-353e-4fe7-abf8-c7998b0a89a5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\n",
            "=======================================================\n",
            "\n",
            "3. MARKETING DOMAIN: Customer Segmentation\n",
            "---------------------------------------------\n",
            "\n",
            "============================================================\n",
            "SUMMARY COMPARISON ACROSS DOMAINS\n",
            "============================================================\n",
            "     Domain  OvO_Accuracy  OvR_Accuracy Best_Strategy\n",
            "Credit Risk      0.754167      0.708333           OvO\n",
            "\n",
            "Overall Performance:\n",
            "OvO was better in 1 out of 1 domains\n",
            "OvR was better in 0 out of 1 domains\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
        "print(\"One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "def create_education_dataset():\n",
        "    \"\"\"Create a synthetic student performance dataset\"\"\"\n",
        "    print(\"\\n4. EDUCATION DOMAIN: Student Performance Prediction\")\n",
        "    print(\"-\" * 45)\n",
        "\n",
        "    # Simulate student data: study_hours, attendance, previous_grades, extracurricular, parental_support\n",
        "    X, y = make_classification(\n",
        "        n_samples=900, n_features=5, n_informative=5, n_redundant=0,\n",
        "        n_classes=3, n_clusters_per_class=1, random_state=42\n",
        "    )\n",
        "\n",
        "    # Transform to realistic education ranges\n",
        "    X[:, 0] = X[:, 0] * 15 + 10       # Study hours: 10-25 hrs/week\n",
        "    X[:, 1] = X[:, 1] * 30 + 70       # Attendance: 70-100%\n",
        "    X[:, 2] = X[:, 2] * 20 + 70       # Previous grades: 70-90%\n",
        "    X[:, 3] = X[:, 3] * 10 + 5        # Extracurricular: 5-15 hrs/month\n",
        "    X[:, 4] = X[:, 4] * 4 + 3         # Parental support: 3-7 (scale 1-7)\n",
        "\n",
        "    class_names = ['Low Performance', 'Average Performance', 'High Performance']\n",
        "    feature_names = ['Study Hours', 'Attendance %', 'Previous Grades', 'Extracurricular Hours', 'Parental Support']\n",
        "\n",
        "    return X, y, class_names, feature_names, \"Student Performance\"\n",
        "\n",
        "def evaluate_strategies(X, y, class_names, feature_names, domain_name):\n",
        "    \"\"\"Evaluate OvO vs OvR strategies for a given dataset\"\"\"\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDomain: {domain_name}\")\n",
        "    print(f\"Classes: {class_names}\")\n",
        "    print(f\"Features: {feature_names}\")\n",
        "    print(f\"Training samples: {len(X_train)}\")\n",
        "    print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "    # Create base classifier\n",
        "    base_clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "    # Apply both strategies\n",
        "    ovo_clf = OneVsOneClassifier(base_clf)\n",
        "    ovr_clf = OneVsRestClassifier(base_clf)\n",
        "\n",
        "    # Train and evaluate\n",
        "    ovo_clf.fit(X_train, y_train)\n",
        "    ovr_clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred_ovo = ovo_clf.predict(X_test)\n",
        "    y_pred_ovr = ovr_clf.predict(X_test)\n",
        "\n",
        "    # Scores\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    ovo_score = accuracy_score(y_test, y_pred_ovo)\n",
        "    ovr_score = accuracy_score(y_test, y_pred_ovr)\n",
        "\n",
        "    print(f\"\\nResults:\")\n",
        "    print(f\"One-vs-One (OvO) Accuracy: {ovo_score:.4f}\")\n",
        "    print(f\"One-vs-Rest (OvR) Accuracy: {ovr_score:.4f}\")\n",
        "\n",
        "    # Show detailed classification report for the better performing strategy\n",
        "    best_strategy = \"OvO\" if ovo_score >= ovr_score else \"OvR\"\n",
        "    best_clf = ovo_clf if ovo_score >= ovr_score else ovr_clf\n",
        "    best_pred = y_pred_ovo if ovo_score >= ovr_score else y_pred_ovr\n",
        "\n",
        "    from sklearn.metrics import classification_report\n",
        "    print(f\"\\nBest Strategy: {best_strategy}\")\n",
        "    print(\"Detailed Classification Report:\")\n",
        "    print(classification_report(y_test, best_pred, target_names=class_names))\n",
        "\n",
        "    return ovo_score, ovr_score\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Create datasets from different domains\n",
        "    datasets = [\n",
        "        create_education_dataset()\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Evaluate each dataset\n",
        "    for dataset in datasets:\n",
        "        X, y, class_names, feature_names, domain_name = dataset\n",
        "        ovo_score, ovr_score = evaluate_strategies(X, y, class_names, feature_names, domain_name)\n",
        "        results.append({\n",
        "            'Domain': domain_name,\n",
        "            'OvO_Accuracy': ovo_score,\n",
        "            'OvR_Accuracy': ovr_score,\n",
        "            'Best_Strategy': 'OvO' if ovo_score >= ovr_score else 'OvR'\n",
        "        })\n",
        "\n",
        "    # Summary comparison\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"SUMMARY COMPARISON ACROSS DOMAINS\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    # Overall analysis\n",
        "    ovo_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvO')\n",
        "    ovr_wins = sum(1 for r in results if r['Best_Strategy'] == 'OvR')\n",
        "\n",
        "    print(f\"\\nOverall Performance:\")\n",
        "    print(f\"OvO was better in {ovo_wins} out of {len(datasets)} domains\")\n",
        "    print(f\"OvR was better in {ovr_wins} out of {len(datasets)} domains\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wmiBWSTXhUm",
        "outputId": "5bfad7ff-d1fb-42cc-b77d-b580d67aad67"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) and One-vs-Rest (OvR) Algorithms Demo\n",
            "=======================================================\n",
            "\n",
            "4. EDUCATION DOMAIN: Student Performance Prediction\n",
            "---------------------------------------------\n",
            "\n",
            "Domain: Student Performance\n",
            "Classes: ['Low Performance', 'Average Performance', 'High Performance']\n",
            "Features: ['Study Hours', 'Attendance %', 'Previous Grades', 'Extracurricular Hours', 'Parental Support']\n",
            "Training samples: 630\n",
            "Test samples: 270\n",
            "\n",
            "Results:\n",
            "One-vs-One (OvO) Accuracy: 0.8630\n",
            "One-vs-Rest (OvR) Accuracy: 0.8481\n",
            "\n",
            "Best Strategy: OvO\n",
            "Detailed Classification Report:\n",
            "                     precision    recall  f1-score   support\n",
            "\n",
            "    Low Performance       0.80      0.79      0.80        91\n",
            "Average Performance       0.86      0.80      0.83        90\n",
            "   High Performance       0.93      1.00      0.96        89\n",
            "\n",
            "           accuracy                           0.86       270\n",
            "          macro avg       0.86      0.86      0.86       270\n",
            "       weighted avg       0.86      0.86      0.86       270\n",
            "\n",
            "\n",
            "============================================================\n",
            "SUMMARY COMPARISON ACROSS DOMAINS\n",
            "============================================================\n",
            "             Domain  OvO_Accuracy  OvR_Accuracy Best_Strategy\n",
            "Student Performance      0.862963      0.848148           OvO\n",
            "\n",
            "Overall Performance:\n",
            "OvO was better in 1 out of 1 domains\n",
            "OvR was better in 0 out of 1 domains\n"
          ]
        }
      ]
    }
  ]
}